
# import os
# import tensorflow as tf
# import config, data_loader, model as model_builder

# def main():
#     # 1. Setup GPU
#     gpus = tf.config.experimental.list_physical_devices('GPU')
#     if gpus:
#         try:
#             for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)
#         except RuntimeError: pass

#     print("üîπ ƒêang t·∫£i d·ªØ li·ªáu ƒë·ªÉ h·ªçc ti·∫øp...")
    
#     # 2. Load l·∫°i d·ªØ li·ªáu (nh∆∞ train.py)
#     train_img_paths, train_labels = data_loader.clean_labels(config.TRAIN_LABELS)
#     valid_img_paths, valid_labels = data_loader.clean_labels(config.VALID_LABELS)
#     char_to_num, num_to_char = data_loader.build_vocabulary(train_labels + valid_labels)
    
#     train_ds = data_loader.prepare_dataset(train_img_paths, train_labels, char_to_num)
#     valid_ds = data_loader.prepare_dataset(valid_img_paths, valid_labels, char_to_num)

#     # 3. QUAN TR·ªåNG: Load l·∫°i model c≈© (Best Model)
#     model_path = "checkpoints/best_model.keras"
#     if not os.path.exists(model_path):
#         print(" Kh√¥ng t√¨m th·∫•y model c≈©! B·∫°n ph·∫£i ch·∫°y train.py tr∆∞·ªõc.")
#         return
    
#     print(f" ƒêang load model t·ª´: {model_path}")
#     # Load model v·ªõi custom object
#     model = tf.keras.models.load_model(model_path, custom_objects={"CTCLayer": model_builder.CTCLayer})

#     # 4. THI·∫æT L·∫¨P H·ªåC CH·∫¨M (Fine-tuning)
#     # Gi·∫£m Learning Rate xu·ªëng 10 l·∫ßn (0.001 -> 0.0001) ƒë·ªÉ h·ªçc chi ti·∫øt
#     NEW_LEARNING_RATE = 0.00001
#     print(f" Thi·∫øt l·∫≠p t·ªëc ƒë·ªô h·ªçc m·ªõi: {NEW_LEARNING_RATE}")
    
#     optimizer = tf.keras.optimizers.Adam(learning_rate=NEW_LEARNING_RATE, clipnorm=1.0)
#     model.compile(optimizer=optimizer)

#     # 5. Callbacks
#     checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
#         "checkpoints/best_model.keras", 
#         monitor="val_loss", 
#         save_best_only=True, 
#         mode="min",
#         verbose=1
#     )
#     early_stopping_cb = tf.keras.callbacks.EarlyStopping(
#         monitor="val_loss", patience=5, restore_best_weights=True, verbose=1
#     )

#     # 6. B·∫Øt ƒë·∫ßu h·ªçc ti·∫øp th√™m 50 Epochs n·ªØa
#     print("\n B·∫Øt ƒë·∫ßu Fine-tuning...")
#     history = model.fit(
#         train_ds,
#         validation_data=valid_ds,
#         epochs=50, # Ch·∫°y th√™m 50 v√≤ng n·ªØa
#         callbacks=[checkpoint_cb, early_stopping_cb]
#     )
#     print("\n Ho√†n t·∫•t Fine-tuning!")

# if __name__ == "__main__":
#     main()



import os
import tensorflow as tf
import config, data_loader, model as model_builder


def main():

    # 1. GPU
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError:
            pass

    print("üîπ ƒêang load d·ªØ li·ªáu ƒë·ªÉ Fine-tune...")

    # 2. Load dataset
    train_img_paths, train_labels = data_loader.clean_labels(config.TRAIN_LABELS)
    valid_img_paths, valid_labels = data_loader.clean_labels(config.VALID_LABELS)

    # D√πng l·∫°i t·ª´ ƒëi·ªÉn CHU·∫®N
    char_to_num, num_to_char = data_loader.build_vocabulary(
        train_labels + valid_labels
    )

    train_ds = data_loader.prepare_dataset(train_img_paths, train_labels, char_to_num)
    valid_ds = data_loader.prepare_dataset(valid_img_paths, valid_labels, char_to_num)

    # 3. Load model c≈© (nh∆∞ predict.py)
    model_path = r"/home/tudong/src/checkpoints/best_model.keras"

    if not os.path.exists(model_path):
        print("‚ùå Kh√¥ng t√¨m th·∫•y model c≈©!")
        return

    print(f"üîπ Load model t·ª´: {model_path}")

    model = tf.keras.models.load_model(
        model_path,
        custom_objects={
            "CTCLayer": model_builder.CTCLayer,
            "conv_block": model_builder.conv_block
        }
    )

    # 4. Fine-tune v·ªõi LR nh·ªè
    NEW_LR = 1e-5
    print(f"üîπ Learning Rate m·ªõi: {NEW_LR}")

    optimizer = tf.keras.optimizers.Adam(
        learning_rate=NEW_LR, 
        clipnorm=1.0
    )
    model.compile(optimizer=optimizer)

    # 5. Callbacks
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
        model_path,
        monitor="val_loss",
        save_best_only=True,
        mode="min",
        verbose=1
    )

    early_stop_cb = tf.keras.callbacks.EarlyStopping(
        monitor="val_loss",
        patience=5,
        restore_best_weights=True,
        verbose=1
    )

    # 6. Train ti·∫øp
    print("\n B·∫ÆT ƒê·∫¶U FINE-TUNING...\n")

    model.fit(
        train_ds,
        validation_data=valid_ds,
        epochs=10,
        callbacks=[checkpoint_cb, early_stop_cb]
    )

    print("\n Fine-tuning ho√†n t·∫•t!")


if __name__ == "__main__":
    main()
