
import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
from src import config, data_loader, model as model_builder

# 1. Cáº¥u hÃ¬nh trang Web
st.set_page_config(page_title="Nháº­n dáº¡ng chá»¯ viáº¿t tay", page_icon="âœï¸")
st.title("âœï¸ á»¨ng dá»¥ng Nháº­n dáº¡ng Chá»¯ viáº¿t tay (OCR)")
st.write("Táº£i áº£nh chá»©a dÃ²ng chá»¯ viáº¿t tay lÃªn Ä‘á»ƒ AI Ä‘á»c nhÃ©!")

# 2. HÃ m Load Model (DÃ¹ng cache Ä‘á»ƒ khÃ´ng pháº£i load láº¡i má»—i láº§n f5)
@st.cache_resource
def load_ocr_model():
    # Load láº¡i bá»™ tá»« Ä‘iá»ƒn
    train_labels = data_loader.clean_labels(config.TRAIN_LABELS)[1]
    valid_labels = data_loader.clean_labels(config.VALID_LABELS)[1]
    char_to_num, num_to_char = data_loader.build_vocabulary(train_labels + valid_labels)
    
    # Load model
    model_path = "checkpoints/best_model.keras"
    model = tf.keras.models.load_model(
        model_path, 
        custom_objects={"CTCLayer": model_builder.CTCLayer}
    )
    
    # TÃ¡ch láº¥y pháº§n dá»± Ä‘oÃ¡n (giá»‘ng predict.py)
    prediction_model = tf.keras.models.Model(
        inputs=model.inputs[0], 
        outputs=model.get_layer(name="dense_1").output
    )
    return prediction_model, num_to_char

# 3. HÃ m giáº£i mÃ£ káº¿t quáº£
def decode_batch_predictions(pred, num_to_char):
    input_len = np.ones(pred.shape[0]) * pred.shape[1]
    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :config.MAX_LABEL_LENGTH]
    output_text = []
    for res in results:
        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode("utf-8")
        # Lá»c bá» kÃ½ tá»± láº¡
        res = res.replace("[UNK]", "").strip() 
        output_text.append(res)
    return output_text

# 4. HÃ m xá»­ lÃ½ áº£nh tá»« Upload
def process_uploaded_image(image):
    # Chuyá»ƒn sang áº£nh xÃ¡m
    image = image.convert("L")
    # Chuyá»ƒn thÃ nh máº£ng sá»‘
    image = tf.keras.preprocessing.image.img_to_array(image)
    # Resize theo Ä‘Ãºng chuáº©n training (HÃ m nÃ y láº¥y tá»« data_loader)
    image = data_loader.distortion_free_resize(image, (config.IMG_WIDTH, config.IMG_HEIGHT))
    # Chuáº©n hÃ³a vá» 0-1
    image = tf.cast(image, tf.float32) / 255.0
    # ThÃªm chiá»u batch (1, 1024, 32, 1)
    image = tf.expand_dims(image, axis=0)
    return image

# --- GIAO DIá»†N CHÃNH ---

try:
    # Load model ngay khi vÃ o web
    with st.spinner("Äang khá»Ÿi Ä‘á»™ng AI... Äá»£i chÃºt nhÃ©!"):
        model, num_to_char = load_ocr_model()
    st.success("AI Ä‘Ã£ sáºµn sÃ ng!")

    # NÃºt upload file
    uploaded_file = st.file_uploader("Chá»n áº£nh (PNG, JPG)", type=["png", "jpg", "jpeg"])

    if uploaded_file is not None:
        # Hiá»ƒn thá»‹ áº£nh gá»‘c
        image = Image.open(uploaded_file)
        st.image(image, caption="áº¢nh báº¡n vá»«a táº£i lÃªn", use_container_width=True)

        # NÃºt báº¥m Dá»± Ä‘oÃ¡n
        if st.button("Äá»c chá»¯ trong áº£nh"):
            with st.spinner("AI Ä‘ang Ä‘á»c..."):
                # Xá»­ lÃ½ áº£nh
                processed_img = process_uploaded_image(image)
                
                # Dá»± Ä‘oÃ¡n
                preds = model.predict(processed_img)
                pred_text = decode_batch_predictions(preds, num_to_char)[0]
                
                # Hiá»‡n káº¿t quáº£ to Ä‘áº¹p
                st.markdown("### ğŸ¯ Káº¿t quáº£:")
                st.code(pred_text, language="text")

except Exception as e:
    st.error(f"CÃ³ lá»—i xáº£y ra: {e}")
    st.warning("HÃ£y cháº¯c cháº¯n báº¡n Ä‘Ã£ cháº¡y train.py xong vÃ  cÃ³ file 'checkpoints/best_model.keras' nhÃ©!")