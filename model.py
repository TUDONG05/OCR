# import tensorflow as tf
# from tensorflow.keras import layers, models
# import config

# def ctc_batch_cost(y_true, y_pred, input_length, label_length):
#     return tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)

# class CTCLayer(layers.Layer):
#     def __init__(self, name=None, **kwargs):
#         super().__init__(name=name, **kwargs)
#         self.loss_fn = ctc_batch_cost

#     def call(self, y_true, y_pred):
#         batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")
#         input_length = tf.cast(tf.shape(y_pred)[1], dtype="int64")
#         input_length = input_length * tf.ones(shape=(batch_len, 1), dtype="int64")

#         # ƒê·∫øm ƒë√∫ng s·ªë k√Ω t·ª± th·ª±c
#         label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype="int64")

#         loss = self.loss_fn(y_true, y_pred, input_length, label_length)
#         self.add_loss(loss)
#         return y_pred

#     def get_config(self):
#         config = super().get_config()
#         return config

# def build_model(vocab_size):
#     input_img = layers.Input(shape=(config.IMG_WIDTH, config.IMG_HEIGHT, 1), name="image", dtype="float32")
#     labels = layers.Input(name="label", shape=(None,), dtype="float32")

#     # CNN Block 1
#     x = layers.Conv2D(32, (3, 3), activation="relu", kernel_initializer="he_normal", padding="same")(input_img)
#     x = layers.MaxPooling2D((2, 2))(x) # Gi·∫£m l·∫ßn 1 (1024 -> 512)
    
#     # CNN Block 2
#     x = layers.Conv2D(64, (3, 3), activation="relu", kernel_initializer="he_normal", padding="same")(x)
#     # --- ƒê√É X√ìA L·ªöP MAX POOLING ·ªû ƒê√ÇY ƒê·ªÇ TƒÇNG ƒê·ªò PH√ÇN GI·∫¢I ---
#     # x = layers.MaxPooling2D((2, 2))(x) 

#     new_shape = ((config.IMG_WIDTH // 2), (config.IMG_HEIGHT // 2) * 64)
#     x = layers.Reshape(target_shape=new_shape)(x)
    
#     x = layers.Dense(64, activation="relu")(x)
#     x = layers.Dropout(0.2)(x)

#     # Bi-LSTM
#     x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)
#     x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)

#     x = layers.Dense(vocab_size + 1, activation="softmax")(x)
#     output = CTCLayer(name="ctc_loss")(labels, x)

#     model = models.Model(inputs=[input_img, labels], outputs=output)
    
#     # Optimizer (Gi·ªØ nguy√™n clipnorm)
#     optimizer = tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE, clipnorm=1.0)
#     model.compile(optimizer=optimizer)
#     return model


import tensorflow as tf
from tensorflow.keras import layers, models
import config

def ctc_batch_cost(y_true, y_pred, input_length, label_length):
    return tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)

class CTCLayer(layers.Layer):
    def __init__(self, name=None, **kwargs):
        super().__init__(name=name, **kwargs)
        self.loss_fn = ctc_batch_cost

    def call(self, y_true, y_pred):
        batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")
        input_length = tf.cast(tf.shape(y_pred)[1], dtype="int64")
        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype="int64")

        label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype="int64")
        loss = self.loss_fn(y_true, y_pred, input_length, label_length)

        self.add_loss(loss)
        return y_pred

    def get_config(self):
        return super().get_config()


def conv_block(x, filters):
    x = layers.Conv2D(filters, (3, 3), padding='same', kernel_initializer="he_normal")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    return x


def build_model(vocab_size):
    input_img = layers.Input(
        shape=(config.IMG_WIDTH, config.IMG_HEIGHT, 1),
        name="image",
        dtype="float32"
    )
    labels = layers.Input(name="label", shape=(None,), dtype="float32")

    x = input_img

    # -------------------------------
    # üî• 6 L·ªöP CNN (ƒê√öNG CHU·∫®N)
    # -------------------------------

    # Block 1
    x = conv_block(x, 64)
    x = conv_block(x, 64)
    x = layers.MaxPooling2D((2, 2))(x)

    # Block 2
    x = conv_block(x, 128)
    x = conv_block(x, 128)
    x = layers.MaxPooling2D((2, 2))(x)

    # Block 3
    x = conv_block(x, 256)
    x = conv_block(x, 256)
    x = layers.MaxPooling2D((2, 1))(x)

    # -------------------------------
    # üî• RESHAPE ‚Üí TIME STEPS
    # -------------------------------
    shape = x.shape
    new_w = shape[1]
    new_features = shape[2] * shape[3]
    x = layers.Reshape((new_w, new_features))(x)

    x = layers.Dense(256, activation="relu")(x)
    x = layers.Dropout(0.25)(x)

    # -------------------------------
    # üî• BI-LSTM (256 ‚Üí 128)
    # -------------------------------
    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)
    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)

    # -------------------------------
    # üî• OUTPUT
    # -------------------------------
    x = layers.Dense(vocab_size + 1, activation="softmax", name="predictions")(x)

    output = CTCLayer(name="ctc_loss")(labels, x)

    model = models.Model(inputs=[input_img, labels], outputs=output)

    optimizer = tf.keras.optimizers.Adam(
        learning_rate=config.LEARNING_RATE,
        clipnorm=1.0
    )
    model.compile(optimizer=optimizer)

    return model
